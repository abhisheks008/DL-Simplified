# Dataset Description for Drone Navigation Project

## Environment State Representation:
The drone's environment is represented as a 2D grid where each cell can represent different entities:
- **Free Space**: Areas where the drone can navigate.
- **Obstacles**: Fixed points on the grid that the drone must avoid.
  - Example: (6, 6), (7, 7)
- **Target**: The desired destination for the drone to reach.
  - Example: (8, 8)

## State Space:
The state of the drone is represented as a 2D NumPy array with two elements:
- **state[0]**: The x-coordinate of the drone's current position.
- **state[1]**: The y-coordinate of the drone's current position.

The observation space is defined within the bounds of the grid, specifically [0, 10], indicating that the drone can move within a 10x10 grid.

## Action Space:
The actions available to the drone are represented as discrete movements within the grid:
- **0**: Up
- **1**: Down
- **2**: Left
- **3**: Right
- **4**: Up-Right
- **5**: Up-Left
- **6**: Down-Right
- **7**: Down-Left

## Sample Data:
While the environment does not rely on external datasets, the positions of obstacles and the target can be seen as parameters that define the specific scenario of the navigation task.

## Data Generation:
The grid layout, obstacle positions, and target location can be adjusted as necessary to create various scenarios for testing the drone's navigation algorithm.

## Future Dataset Enhancements:
Future versions of the project may incorporate more complex environments with variable obstacle positions, dynamic targets, and real-world data, enhancing the robustness and adaptability of the navigation algorithm.

